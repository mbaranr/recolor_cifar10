# Generative Approaches to CIFAR10 Colourization
This repository showcases two approaches to the coulourization task of CIFAR10 images: Auto Encoder U-Net and Conditional GAN. Over the last decade, the process of automatic colorization has been studied thoroughly due to its vast applications such as colourization of grayscale images and restoration of aged and/or degraded images. This problem is highly ill-posed due to the extremely large degrees of freedom during the assignment of color information. In this approach, I attempted to fully generalize this procedure using a conditional Deep Convolutional Generative Adversarial Network (DCGAN). The network is trained over a dataset that is publicly available, CIFAR10.

## Architecture

The GAN architecture uses a **U-Net**, introduced by ([Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597), like fully convolutional architecture  (with concatenation of opposite layers) for the generator, and the G loss function is L1 regularized, which produces an effect where the generator is forced to produce results that are similar to the ground truth on the pixel level. This will theoretically preserve the structure of the original images and prevent the generator from assigning arbitrary colors to pixels just to fool the discriminator. The generator takes the grayscaled image as an input, while the discrimator takes either the original image or generated image plus the condition, which is the grayscaled image in this case.

<div align="center">
  <img src="https://github.com/M4mbo/Generative_Approaches_to_CIFAR10_Colourization/assets/115642529/89e36747-deb9-4ca4-a300-02a4b941312d" width="400"/>
  <p><em>U-Net Architecture. Gray arrows represent the skip connections from encoder to the mirroring decoder layer.</em></p>
</div>


### DCGAN 


<div align="center">
  <img src="https://github.com/M4mbo/Generative-Colourization-Approaches-to-CIFAR10/assets/115642529/0e01f3af-3d12-4d28-981d-7041f209c4d5" height="350"/>
  <img src="https://github.com/M4mbo/Generative-Colourization-Approaches-to-CIFAR10/assets/115642529/897686d0-4c8b-4e7b-965e-bad6145c3f76" height="350"/>
</div>

## Auto Enconder 

<div align="center">
  <img src="https://github.com/M4mbo/Generative-Colourization-Approaches-to-CIFAR10/assets/115642529/cfb05896-1caa-4ef1-8ef0-374e7862e5b9" height="300" width="650"/>
  <img src="https://github.com/M4mbo/Generative-Colourization-Approaches-to-CIFAR10/assets/115642529/fd13dc37-20f7-418d-8018-219b2f44c98a" height="300" width="350"/>
</div>

## Summary

GAN generated images had a clear visual improvement over those generated by the U-Net alone. These were more vibrant whereas, the results from the auto encoder suffered from a light hue and phenomenon referred as "sepia effect". In some cases, the GAN was able to nearly replicate the ground truth. It was even able to colorize reasonably well on one of the images where the ground truth was "close" to grayscale. Nonetheless, both models where trained for only 20 epochs, and it appeared that the loss function continued to have a negative gradient for the last epoch, so they probably need more time to converge.

## Credits

* [mbaranr](https://github.com/mbaranr) - Code.
* [LMH](https://www.lmh.ox.ac.uk/) summer program on 'AI and ML: Advanced Applications' - Theory.


